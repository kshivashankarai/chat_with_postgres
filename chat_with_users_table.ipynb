{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_QUERY_TEMPLATE=\"\"\"\n",
    "Database Structure:{table_structure}\n",
    "\n",
    "You are an expert postgres query builder. Given the above postgres database structure, it is your job to create a executable query to fetch the data for the following question. \n",
    "\n",
    "Question:{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_TABLE_STRUCTURE=\"CREATE TABLE 'users' ('id' INTEGER NOT NULL DEFAULT 'nextval(''users_id_seq''::regclass)','created_at' TIMESTAMP NULL DEFAULT NULL,'updated_at' TIMESTAMP NULL DEFAULT NULL,'updated_by' INTEGER NOT NULL DEFAULT '0','status' CHAR(1) NOT NULL DEFAULT 'Y','code' CHAR(15) NULL DEFAULT NULL,'id_department' INTEGER NOT NULL DEFAULT '0','first_name' CHAR(255) NULL DEFAULT NULL,'middle_name' CHAR(255) NULL DEFAULT NULL,'last_name' CHAR(255) NULL DEFAULT NULL,'email_id' CHAR(125) NULL DEFAULT NULL,'gender' INTEGER NOT NULL DEFAULT '1','nationality' INTEGER NULL DEFAULT NULL,'date_of_birth' DATE NULL DEFAULT NULL,'marital_status' INTEGER NOT NULL DEFAULT '1','mobile_no' CHAR(20) NULL DEFAULT NULL,'department_id' CHAR(255) NULL DEFAULT NULL,PRIMARY KEY ('id'),);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(prompt):\n",
    "    \n",
    "    llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    \n",
    "    postgres_query_generator = PromptTemplate(\n",
    "        input_variables=[\"table_structure\",\"question\"],\n",
    "        template=GENERATE_QUERY_TEMPLATE\n",
    "    )\n",
    "    \n",
    "    query_chain=LLMChain(llm=llm, prompt=postgres_query_generator, output_key=\"query\", verbose=False)\n",
    "    \n",
    "    generate_query_chain=SequentialChain(\n",
    "        chains=[query_chain], \n",
    "        input_variables=[\"table_structure\", \"question\"],\n",
    "        output_variables=[\"query\"], \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    response_one=generate_query_chain(\n",
    "        {\n",
    "            \"table_structure\": USERS_TABLE_STRUCTURE,\n",
    "            \"question\": prompt\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    postgres_query = response_one['query']\n",
    "    \n",
    "    return postgres_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USERNAME = os.getenv(\"DB_USERNAME\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_connection():\n",
    "    connection = psycopg2.connect(\n",
    "        host = DB_HOST,\n",
    "        database = DB_NAME,\n",
    "        user = DB_USERNAME,\n",
    "        password = DB_PASSWORD\n",
    "    )\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_response(postgres_query):\n",
    "    postgres_connection = create_connection()\n",
    "    results = execute_query(postgres_connection, postgres_query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are an helping assistant. generate a response for question \"{question}\" using the {db_response}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt, results):\n",
    "    \n",
    "    llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "    \n",
    "    response_generator = PromptTemplate(\n",
    "        input_variables=[\"question\",\"db_response\"],\n",
    "        template=RESPONSE_TEMPLATE\n",
    "    )\n",
    "    \n",
    "    response_chain=LLMChain(llm=llm, prompt=response_generator, output_key=\"answer\", verbose=False)\n",
    "    \n",
    "    generate_response_chain=SequentialChain(\n",
    "        chains=[response_chain], \n",
    "        input_variables=[\"question\", \"db_response\"],\n",
    "        output_variables=[\"answer\"], \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    response_two=generate_response_chain(\n",
    "        {\n",
    "            \"question\": prompt,\n",
    "            \"db_response\": results\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    answer = response_two[\"answer\"]\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_users(prompt):\n",
    "\n",
    "    generated_query = generate_query(prompt)\n",
    "\n",
    "    generated_query = generated_query.replace(\"\\n\", \" \")\n",
    "\n",
    "    generated_query\n",
    "\n",
    "    query_db_response = get_query_response(generated_query)\n",
    "\n",
    "    query_db_response\n",
    "\n",
    "    answer = generate_answer(prompt, query_db_response)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_prompt = input(\"Ask me about users table: \")\n",
    "    if input_prompt == 'stop':\n",
    "        break\n",
    "    else:\n",
    "        output = chat_with_users(input_prompt)\n",
    "        print(input_prompt)\n",
    "        print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
